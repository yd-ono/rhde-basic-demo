---

top_line_variables:
  type: demo
  name: summit_connect_2023

local_services:
  - name: dnsmasq
    privileged: true
    templates:
      - src: dnsmasq.conf.j2
        dest: dnsmasq.conf
        vars:
          upstream_dns_servers:
            - 8.8.8.8
            - 8.8.4.4
          internal_address: 192.168.1.1
          internal_netmask: 24
          dhcp_range_start: 192.168.1.5
          dhcp_range_end: 192.168.1.254
          dhcp_lease_time: 12h
      - src: dnsmasq.hosts.j2
        dest: dnsmasq.hosts
        vars:
          dns_entries:
            - record: "controller.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "image-builder.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "gitea.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "attendance.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "ipxe.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "ostree-repo.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "exercises.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
            - record: "attendance.{{ ec2_name_prefix }}.{{ workshop_dns_zone }}"
              address: "{{ internal_address }}"
    post_tasks:
      - dnsmasq-update-etc-hosts.yml
    containerfile: dnsmasq-containerfile
  - name: reverse-proxy
    containerfile: reverse-proxy-containerfile
    pre_tasks:
      - reverse-proxy-copy-certs.yml
    templates:
      - src: reverse-proxy-nginx.conf.j2
        dest: nginx.conf
        vars:
          proxied_services:
            - name: controller
              proxy_pass: "https://localhost:10443/"
              proxy_advanced_options:
                - proxy_ssl_verify off
            - name: image-builder
              proxy_pass: "https://localhost:9090/"
              web_socket: true
              proxy_advanced_options:
                - proxy_ssl_verify off
            - name: gitea
              proxy_pass: "http://localhost:3001/"
            - name: ostree-repo
              proxy_pass: "http://localhost:18080/"
            - name: attendance
              proxy_pass: "http://localhost:3000/"
              web_socket: true
            - name: eda
              proxy_pass: "http://localhost:5000/"
            - name: ipxe
              proxy_pass: "http://localhost:8081/"
  - name: database
    containerfile: database-containerfile
    templates:
      - src: database-postgresql.conf.j2
        dest: postgresql.conf
      - src: database-db-start.sh.j2
        dest: db-start.sh
        vars:
          databases:
            - name: gitea
              username: gitea
              password: gitea
  - name: gitea
    containerfile: gitea-containerfile
    templates:
      - src: gitea-app.ini.j2
        dest: app.ini
  - name: attendance
    containerfile: attendance-containerfile
    pre_tasks:
      - attendance-student-pages.yml
      - attendance-rsync-site.yml
    templates:
      - src: attendance-App.js.j2
        dest: attendance/src/App.js
      - src: attendance-index.js.j2
        dest: attendance/src/pages/index.js
  - name: tftp
    containerfile: tftp-containerfile
    pre_tasks:
      - tftp-download-chainload-files.yml
  - name: ostree-repo
    containerfile: ostree-repo-containerfile
    pre_tasks:
      - ostree-repo-copy-repo.yml
    files:
      - src: ostree-repo-nginx.conf
        dest: nginx.conf
  - name: ipxe
    containerfile: ipxe-containerfile
    pre_tasks:
      - ipxe-get-boot-iso.yml
      - ipxe-student-kickstarts.yml
    post_tasks:
      - ipxe-cleanup-boot-iso.yml
    templates:
      - src: workshop.ipxe.j2
        dest: workshop.ipxe
    files:
      - src: ipxe-nginx.conf
        dest: nginx.conf
pods:
  - name: "{{ top_line_variables.type }}-{{ top_line_variables.name }}-priv"
    privileged: true
    definition:
      apiVersion: v1
      kind: Pod
      metadata:
        annotations:
          # should make these vars at some point
          io.podman.annotations.autoremove/demo-summit_connect_2023-priv: "FALSE"
          io.podman.annotations.init/demo-summit_connect_2023-priv: "FALSE"
          io.podman.annotations.privileged/demo-summit_connect_2023-priv: "TRUE"
          io.podman.annotations.publish-all/demo-summit_connect_2023-priv: "FALSE"
        labels:
          app: "{{ top_line_variables.type }}-{{ top_line_variables.name }}-priv"
        name: "{{ top_line_variables.type }}-{{ top_line_variables.name }}-priv"
      spec:
        hostNetwork: true
        containers:
          - name: dnsmasq
            image: dnsmasq:latest
            securityContext:
              privileged: true
  - name: "{{ top_line_variables.type }}-{{ top_line_variables.name }}"
    definition:
      apiVersion: v1
      kind: Pod
      metadata:
        annotations:
          io.podman.annotations.autoremove/demo-summit_connect_2023: "FALSE"
          io.podman.annotations.init/demo-summit_connect_2023: "FALSE"
          io.podman.annotations.privileged/demo-summit_connect_2023: "FALSE"
          io.podman.annotations.publish-all/demo-summit_connect_2023: "FALSE"
        labels:
          app: "{{ top_line_variables.type }}-{{ top_line_variables.name }}"
        name: "{{ top_line_variables.type }}-{{ top_line_variables.name }}"
      spec:
        hostNetwork: true
        containers:
          - name: reverse-proxy
            image: reverse-proxy:latest
          - name: database
            image: database:latest
            volumeMounts:
              - mountPath: /var/lib/pgsql/data
                name: database-data
          - name: gitea
            image: gitea:latest
          - name: attendance
            image: attendance:latest
          - name: tftp
            image: tftp:latest
          - name: ostree-repo
            image: ostree-repo:latest
          - name: ipxe
            image: ipxe:latest
        volumes:
          - name: database-data
            persistentVolumeClaim:
              claimName: "{{ top_line_variables.type }}-{{ top_line_variables.name }}-database"


builder_blueprint_name: rhde-image
images_to_compose:
  # Blank image
  - version: 1.0.0
    type: edge-commit
    packages:
      - vim-enhanced
      - git
      - nano
      - NetworkManager-wifi
      - podman
    customizations:
      files:
        - path: /etc/containers/containers.conf
          mode: '0644'
          user: root
          group: root
          data: "[engine]\nruntime='crun'"
  # Embed application
  - version: 2.0.0
    type: edge-commit
    packages:
      - vim-enhanced
      - git
      - nano
      - NetworkManager-wifi
      - podman
    containers:
      - name: mqtt
        source: quay.io/device-edge-workshops/process-control-mqtt:1.0.0
      - name: simulate
        source: quay.io/device-edge-workshops/process-control-simulate:1.0.0
      - name: control
        source: quay.io/device-edge-workshops/process-control-control:1.0.0
      - name: ui
        source: quay.io/device-edge-workshops/process-control-ui:1.0.0
    customizations:
      files:
        - path: /etc/containers/systemd/process-control.yaml
          mode: '0644'
          user: root
          group: root
          data: "---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: process-control\nspec:\n  containers:\n    - name: mqtt\n      image: docker.io/library/mqtt:latest\n    - name: simulate\n      image: docker.io/library/simulate:latest\n    - name: control\n      image: docker.io/library/control:latest\n    - name: ui\n      image: docker.io/library/ui:latest\n      ports:\n        - containerPort: 1881\n          hostPort: 1881"
        - path: /etc/containers/systemd/process-control.kube
          mode: '0644'
          user: root
          group: root
          data: "[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=network-online.target\n\n[Kube]\nYaml=process-control.yaml\nPublishPort=1881:1881"
        - path: /etc/systemd/system/process-control.service
          mode: '0644'
          user: root
          group: root
          data: "[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=network-online.target\nSourcePath=/etc/containers/systemd/process-control.kube\nRequiresMountsFor=%t/containers\n\n[X-Kube]\nYaml=/etc/containers/systemd/process-control.yaml\nPublishPort=1881:1881\n\n[Service]\nKillMode=mixed\nEnvironment=PODMAN_SYSTEMD_UNIT=%n\nType=notify\nNotifyAccess=all\nSyslogIdentifier=%N\nExecStart=/usr/bin/podman kube play --replace --service-container=true --log-driver passthrough --publish 1881:1881 /etc/containers/systemd/process-control.yaml\nExecStop=/usr/bin/podman kube down /etc/containers/systemd/process-control.yaml"
        - path: /etc/containers/containers.conf
          mode: '0644'
          user: root
          group: root
          data: "[engine]\nruntime='crun'"
      firewall:
        ports:
          - '1881:tcp'
          - '1883:tcp'
      services:
        enabled:
          - process-control
  # Add Greenboot and working application
  - version: 3.0.0
    type: edge-commit
    packages:
      - vim-enhanced
      - git
      - nano
      - NetworkManager-wifi
      - podman
    containers:
      - name: mqtt
        source: quay.io/device-edge-workshops/process-control-mqtt:1.0.0
      - name: simulate
        source: quay.io/device-edge-workshops/process-control-simulate:1.0.0
      - name: control
        source: quay.io/device-edge-workshops/process-control-control:1.0.0
      - name: ui
        source: quay.io/device-edge-workshops/process-control-ui:1.0.0
    customizations:
      files:
        - path: /etc/containers/systemd/process-control.yaml
          mode: '0644'
          user: root
          group: root
          data: "---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: process-control\nspec:\n  containers:\n    - name: mqtt\n      image: docker.io/library/mqtt:latest\n    - name: simulate\n      image: docker.io/library/simulate:latest\n    - name: control\n      image: docker.io/library/control:latest\n    - name: ui\n      image: docker.io/library/ui:latest\n      ports:\n        - containerPort: 1881\n          hostPort: 1881"
        - path: /etc/containers/systemd/process-control.kube
          mode: '0644'
          user: root
          group: root
          data: "[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=network-online.target\n\n[Kube]\nYaml=process-control.yaml\nPublishPort=1881:1881"
        - path: /etc/systemd/system/process-control.service
          mode: '0644'
          user: root
          group: root
          data: "[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=network-online.target\nSourcePath=/etc/containers/systemd/process-control.kube\nRequiresMountsFor=%t/containers\n\n[X-Kube]\nYaml=/etc/containers/systemd/process-control.yaml\nPublishPort=1881:1881\n\n[Service]\nKillMode=mixed\nEnvironment=PODMAN_SYSTEMD_UNIT=%n\nType=notify\nNotifyAccess=all\nSyslogIdentifier=%N\nExecStart=/usr/bin/podman kube play --replace --service-container=true --log-driver passthrough --publish 1881:1881 /etc/containers/systemd/process-control.yaml\nExecStop=/usr/bin/podman kube down /etc/containers/systemd/process-control.yaml"
        - path: /etc/greenboot/check/required.d/application-check.sh
          mode: '0755'
          user: root
          group: root
          data: "#!/bin/bash\n\n/usr/bin/sleep 20\n\nRETURN_CODE=$(/usr/bin/curl -s -o /dev/null -w '%{http_code}' http://localhost:1881)\n\nif [ $RETURN_CODE = '200' ]; then\n    exit 0;\nelse\n    exit 1;\nfi"
        - path: /etc/containers/containers.conf
          mode: '0644'
          user: root
          group: root
          data: "[engine]\nruntime='crun'"
      firewall:
        ports:
          - '1881:tcp'
          - '1883:tcp'
      services:
        enabled:
          - process-control
  # Add Greenboot and broken application, trigger rollback
  - version: 4.0.0
    type: edge-commit
    packages:
      - vim-enhanced
      - git
      - nano
      - NetworkManager-wifi
      - podman
    containers:
      - name: mqtt
        source: quay.io/device-edge-workshops/process-control-mqtt:1.0.0
      - name: simulate
        source: quay.io/device-edge-workshops/process-control-simulate:1.0.0
      - name: control
        source: quay.io/device-edge-workshops/process-control-control:1.0.0
      - name: ui
        source: quay.io/device-edge-workshops/process-control-ui:broken
    customizations:
      files:
        - path: /etc/containers/systemd/process-control.yaml
          mode: '0644'
          user: root
          group: root
          data: "---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: process-control\nspec:\n  containers:\n    - name: mqtt\n      image: docker.io/library/mqtt:latest\n    - name: simulate\n      image: docker.io/library/simulate:latest\n    - name: control\n      image: docker.io/library/control:latest\n    - name: ui\n      image: docker.io/library/ui:latest\n      ports:\n        - containerPort: 1881\n          hostPort: 1881"
        - path: /etc/containers/systemd/process-control.kube
          mode: '0644'
          user: root
          group: root
          data: "[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=network-online.target\n\n[Kube]\nYaml=process-control.yaml\nPublishPort=1881:1881"
        - path: /etc/systemd/system/process-control.service
          mode: '0644'
          user: root
          group: root
          data: "[Install]\nWantedBy=default.target\n\n[Unit]\nAfter=network-online.target\nSourcePath=/etc/containers/systemd/process-control.kube\nRequiresMountsFor=%t/containers\n\n[X-Kube]\nYaml=/etc/containers/systemd/process-control.yaml\nPublishPort=1881:1881\n\n[Service]\nKillMode=mixed\nEnvironment=PODMAN_SYSTEMD_UNIT=%n\nType=notify\nNotifyAccess=all\nSyslogIdentifier=%N\nExecStart=/usr/bin/podman kube play --replace --service-container=true --log-driver passthrough --publish 1881:1881 /etc/containers/systemd/process-control.yaml\nExecStop=/usr/bin/podman kube down /etc/containers/systemd/process-control.yaml"
        - path: /etc/greenboot/check/required.d/application-check.sh
          mode: '0755'
          user: root
          group: root
          data: "#!/bin/bash\n\n/usr/bin/sleep 20\n\nRETURN_CODE=$(/usr/bin/curl -s -o /dev/null -w '%{http_code}' http://localhost:1881)\n\nif [ $RETURN_CODE = '200' ]; then\n    exit 0;\nelse\n    exit 1;\nfi"
        - path: /etc/containers/containers.conf
          mode: '0644'
          user: root
          group: root
          data: "[engine]\nruntime='crun'"
      firewall:
        ports:
          - '1881:tcp'
          - '1883:tcp'
      services:
        enabled:
          - process-control
  # Add Microshift, microshift-greenboot, and embedded application with greenboot check
  - version: 5.0.0
    type: edge-commit
    packages:
      - vim-enhanced
      - git
      - nano
      - NetworkManager-wifi
      - podman
      - microshift
      - microshift-greenboot
    customizations:
      files:
        - path: /etc/greenboot/check/required.d/application-check.sh
          mode: '0755'
          user: root
          group: root
          data: "#!/bin/bash\n\n/usr/bin/sleep 60\n\nRETURN_CODE=$(/usr/bin/curl -s -o /dev/null -w '%{http_code}' http://localhost:1881)\n\nif [ $RETURN_CODE = '200' ]; then\n    exit 0;\nelse\n    exit 1;\nfi"
        - path: /etc/systemd/system/deploy-pull-secret.service
          mode: '0644'
          user: root
          group: root
          data: "[Unit]\nDescription=Deploy pull secret\n\n[Service]\nType=oneshot\nExecStart=/bin/bash /etc/deploy-pull-secret.sh\nRemainAfterExit=yes\n\n[Install]\nWantedBy=multi-user.target"
        - path: /etc/deploy-pull-secret.sh
          mode: '0755'
          user: root
          group: root
          data: "#!/bin/bash\n\n/usr/bin/echo '{{ pull_secret | ansible.builtin.b64encode }}' | base64 -d > /etc/crio/openshift-pull-secret"
        - path: /etc/microshift/manifests/process-control.yaml
          mode: '0644'
          user: root
          group: root
          data: "---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: process-control\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mqtt\nspec:\n  ports:\n  - port: 1883\n    protocol: TCP\n    targetPort: 1883\n  selector:\n    app: mqtt\n  type: NodePort\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mqtt-deployment\nspec:\n  selector:\n    matchLabels:\n      app: mqtt\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: mqtt\n    spec:\n      containers:\n        - name: mqtt\n          image: quay.io/device-edge-workshops/process-control-mqtt:1.0.0\n          ports:\n            - containerPort: 1883\n              name: mqtt-port\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: simulate-deployment\nspec:\n  selector:\n    matchLabels:\n      app: simulate\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: simulate\n    spec:\n      containers:\n        - name: simulate\n          image: quay.io/device-edge-workshops/process-control-simulate-k8s:1.0.0\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: control-deployment\nspec:\n  selector:\n    matchLabels:\n      app: control\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: control\n    spec:\n      containers:\n      - name: control\n        image: quay.io/device-edge-workshops/process-control-control-k8s:3.0.0\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: ui\nspec:\n  ports:\n  - port: 1881\n    protocol: TCP\n    targetPort: 1881\n  selector:\n    app: ui\n  type: NodePort\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ui-deployment\nspec:\n  selector:\n    matchLabels:\n      app: ui\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: ui\n    spec:\n      containers:\n      - name: ui\n        image: quay.io/device-edge-workshops/process-control-ui-k8s:2.0.4\n        ports:\n          - containerPort: 1881\n            name: http-ui-port\n---\nkind: Route\napiVersion: route.openshift.io/v1\nmetadata:\n  name: ui\nspec:\n  path: /ui\n  to:\n    kind: Service\n    name: ui\n  port:\n    targetPort: 1881"
        - path: /etc/microshift/manifests/kustomization.yaml
          mode: '0644'
          user: root
          group: root
          data: "---\napiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: process-control\nresources:\n  - process-control.yaml"
      firewall:
        ports:
          - '6443:tcp'
          - '1881:tcp'
          - '1883:tcp'
      services:
        enabled:
          - microshift
          - deploy-pull-secret
    rhsm_repos:
      - "rhocp-4.13-for-rhel-{{ ansible_distribution_major_version }}-{{ ansible_architecture }}-rpms"
      - "fast-datapath-for-rhel-{{ ansible_distribution_major_version }}-{{ ansible_architecture }}-rpms"

image_builder_http_port: 11080

install_gitea: false
gitea_container: "{{ top_line_variables.type }}-{{ top_line_variables.name }}-gitea"
repo_files:
  - src: templates/README.md.j2
    dest: README.md
  - src: templates/hello-world.yml.j2
    dest: playbooks/hello-world.yml
  - src: "templates/{{ top_line_variables.name }}/compose-image.yml.j2"
    dest: playbooks/compose-image.yml

allowed_external_services:
  - port: 8081
  - port: 10443
  - port: 9090
  - port: 3001
  - port: 3000
  - port: 80
  - port: 443
